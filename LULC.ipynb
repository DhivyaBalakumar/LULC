{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f64ed95-629d-4d3f-bd8a-a4d50569ab5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EuroSAT dataset downloaded and extracted.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import tarfile\n",
    "\n",
    "# Define the URL and download location\n",
    "dataset_url = \"http://madm.dfki.de/files/sentinel/EuroSAT.zip\"\n",
    "dataset_dir = \"EuroSAT\"\n",
    "\n",
    "# Download and extract the dataset\n",
    "if not os.path.exists(dataset_dir):\n",
    "    os.mkdir(dataset_dir)\n",
    "    urllib.request.urlretrieve(dataset_url, os.path.join(dataset_dir, \"EuroSAT.zip\"))\n",
    "    with tarfile.open(os.path.join(dataset_dir, \"EuroSAT.zip\"), \"r:gz\") as tar:\n",
    "        tar.extractall(path=dataset_dir)\n",
    "\n",
    "print(\"EuroSAT dataset downloaded and extracted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83fc6383-8ff5-4268-bbf2-0cb8481c630b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define paths\n",
    "data_dir = \"C:/Users/User/OneDrive/Desktop/LULC/data/data/2750\"\n",
    "\n",
    "# Load and preprocess images\n",
    "def load_data(data_dir):\n",
    "    categories = os.listdir(data_dir)\n",
    "    data = []\n",
    "    labels = []\n",
    "    for category in categories:\n",
    "        category_path = os.path.join(data_dir, category)\n",
    "        for file in os.listdir(category_path):\n",
    "            file_path = os.path.join(category_path, file)\n",
    "            image = tf.keras.preprocessing.image.load_img(file_path, target_size=(64, 64))\n",
    "            image = tf.keras.preprocessing.image.img_to_array(image)\n",
    "            data.append(image)\n",
    "            labels.append(category)\n",
    "    return np.array(data), np.array(labels)\n",
    "\n",
    "# Load data\n",
    "X, y = load_data(data_dir)\n",
    "\n",
    "# Encode labels\n",
    "encoder = LabelEncoder()\n",
    "y_encoded = encoder.fit_transform(y)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda68b67-2572-4044-bf03-11f5aa8f953b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Set data directory\n",
    "data_dir = \"C:/Users/User/OneDrive/Desktop/LULC/data/data/2750\"\n",
    "\n",
    "# Resize images\n",
    "def load_data(data_dir, size=(64, 64)):\n",
    "    categories = os.listdir(data_dir)\n",
    "    data = []\n",
    "    labels = []\n",
    "    for category in categories:\n",
    "        category_path = os.path.join(data_dir, category)\n",
    "        for file in os.listdir(category_path):\n",
    "            file_path = os.path.join(category_path, file)\n",
    "            image = Image.open(file_path)\n",
    "            image = image.resize(size)\n",
    "            image = np.array(image)\n",
    "            data.append(image)\n",
    "            labels.append(category)\n",
    "    return np.array(data), np.array(labels)\n",
    "\n",
    "# Load data\n",
    "X, y = load_data(data_dir)\n",
    "\n",
    "# Encode labels\n",
    "encoder = LabelEncoder()\n",
    "y_encoded = encoder.fit_transform(y)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Flatten images for Random Forest\n",
    "nsamples, nx, ny, nchannels = X_train.shape\n",
    "X_train_flat = X_train.reshape((nsamples, nx * ny * nchannels))\n",
    "\n",
    "nsamples, nx, ny, nchannels = X_test.shape\n",
    "X_test_flat = X_test.reshape((nsamples, nx * ny * nchannels))\n",
    "\n",
    "# Train Random Forest\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train_flat, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test_flat)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred, target_names=encoder.classes_))\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35320153-527e-497d-a075-22638e6e41b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(model, \"lulc_model.joblib\")\n",
    "\n",
    "# Load the model\n",
    "model = joblib.load(\"lulc_model.joblib\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
